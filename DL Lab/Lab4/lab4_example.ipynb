{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary Libraries \n",
    "import torch \n",
    "from matplotlib import pyplot as plt \n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "import torch.nn as nn \n",
    "import numpy as np \n",
    "loss_list = [] \n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Initialize inputs and expected outputs as per the truth table of XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the tensors x1,x2 and y.  \n",
    "# They are the training examples in the dataset for the XOR \n",
    "X = torch.tensor([[0,0],[0,1],[1,0],[1,1]], dtype=torch.float32) \n",
    "Y = torch.tensor([0,1,1,0], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Define XORModel class  - write constructor and forward function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XORModel (nn.Module):\n",
    "    def __init__(self):\n",
    "        super(XORModel, self).__init__()\n",
    "        #self.wtorch.nn.Parameter (torch.rand([1])) \n",
    "        #self.b torch.nn.Parameter (torch.rand([1]))\n",
    "        self.linear1= nn. Linear (2,2,bias=True)\n",
    "        self.activationi nn.Sigmoid()\n",
    "        self.linear2= nn. Linear (2,1,bias=True)\n",
    "        #self.activation2 = nn. ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x= self.linear1(x) \n",
    "        x= self.activation1(x) \n",
    "        x = self.linear2(x) \n",
    "        #x= self.activation2(x) \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Create DataLoader. Write Dataset class with necessary constructors and methods – \n",
    "len() and getitem() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, X, Y): \n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx].to(device), self.Y[idx].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the dataset \n",
    "full_dataset = MyDataset(X, Y) \n",
    "batch_size = 1 \n",
    "#Create the dataloaders for reading data - # This provides a way to read the dataset in batches, also \n",
    "# shuffle the data \n",
    "train_data_loader = DataLoader(full_dataset, batch_size=batch_size, shuffle=True) \n",
    "#Find if CUDA is available to load the model and device  on to the available device CPU/GPU \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "#Load the model to GPU \n",
    "model = XORModel().to(device) \n",
    "print(model) \n",
    "#Add the criterion which is the MSELoss \n",
    "loss_fn = torch.nn.MSELoss() \n",
    "#Optimizers specified in the torch.optim package \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.03)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training an epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch (epoch_index):\n",
    "    totalloss = 0.\n",
    "    # use enumerate(training_Loader) instead of iter \n",
    "    for i, data in enumerate (train_data_loader):\n",
    "        # Every data instance is an input + label pair \n",
    "        inputs, labels = data\n",
    "    \n",
    "        # Zero your gradients for every batch! \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Make predictions for this batch\n",
    "        outputs = model(inputs)\n",
    "    \n",
    "        # Compute the Loss and its gradients\n",
    "        loss = loss_fn (outputs.flatten(), labels)\n",
    "        loss.backward()\n",
    "    \n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "    \n",
    "        # Gather data and report\n",
    "        totalloss += loss.item()\n",
    "    return totalloss/(len(train_data_loader) * batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10000\n",
    "for epoch in range(EPOCHS):\n",
    "    #print('EPOCH {}'.format(epoch + 1))\n",
    "\n",
    "    # Make sure gradient tracking is on, and do a pass over the data \n",
    "    model.train (True)\n",
    "    avg_loss = train_one_epoch(epoch)\n",
    "    loss_list.append(avg_loss)\n",
    "    #loss_list.append(avg_loss.detach().cpu())\n",
    "    #print('LOSS train {}'.format(avg_Loss))\n",
    "    if epoch % 1000 == 0:\n",
    "        print(f'Epoch {epoch}/{EPOCHS}, Loss: {avg_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Inference step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.named_parameters():\n",
    "    print(param)\n",
    "\n",
    "# Model inference - similar to prediction in ML\n",
    "input = torch.tensor([0, 1], dtype=torch.float32).to(device) \n",
    "model.eval()\n",
    "print(\"The input is = {}\".format(input))\n",
    "print(\"Output y predicted ={}\".format(model(input)))\n",
    "#Display the plot\n",
    "plt.plot(loss_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output – Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model parameters= ('linear1.weight', Parameter containing: tensor([[ 0.5413, 0.5890],\n",
    "[-0.1679, 0.6455]], requires_grad=True))\n",
    "Model parameters= ('linear1.bias', Parameter containing: tensor([-0.1505, 0.1357], requires__grad=True))\n",
    "Model parameters= ('linear2.weight', Parameter containing: tensor([[-0.3832, 0.3738]], requires_grad=True))\n",
    "Model parameters= ('linear2.bias', Parameter containing: tensor([0.5562], requires_grad=True))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
